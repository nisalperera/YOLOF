import detectron2.data.transforms as T
import torch
from detectron2.checkpoint import DetectionCheckpointer
from yolof.config import get_cfg
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.detection_utils import read_image
from detectron2.modeling import build_model
from detectron2.data.datasets import register_coco_instances


import cv2
import numpy as np

import cv2
import numpy as np

import torch


class Detectron2GradCAM():
	"""
		Attributes
		----------
		config_file : str
			detectron2 model config file path
		cfg_list : list
			List of additional model configurations
		root_dir : str [optional]
			directory of coco.josn and dataset images for custom dataset registration
		custom_dataset : str [optional]
			Name of the custom dataset to register
		"""
	def __init__(self, cfg, layer_name, grad_cam_instance, cfg_list=[], root_dir=None, custom_dataset=None):

		if custom_dataset and custom_dataset not in DatasetCatalog.list():
			register_coco_instances(custom_dataset, {}, root_dir + "val_damages_100_new.json", root_dir)
			cfg.DATASETS.TRAIN = (custom_dataset,)
			MetadataCatalog.get(custom_dataset)
			DatasetCatalog.get(custom_dataset)

		if len(cfg_list):
			cfg.merge_from_list(cfg_list)
		
		cfg.freeze()
		self.cfg =  cfg
		self.model = build_model(self.cfg)
		checkpointer = DetectionCheckpointer(self.model)
		checkpointer.load(self.cfg.MODEL.WEIGHTS)

		self.layer_name = layer_name
		self.grad_cam_instance = grad_cam_instance

	def _set_input_image(self, img_path):
		image = read_image(img_path, format="BGR")
		image_height, image_width = image.shape[:2]
		transform_gen = T.ResizeShortestEdge(
			[self.cfg.INPUT.MIN_SIZE_TEST, self.cfg.INPUT.MIN_SIZE_TEST], self.cfg.INPUT.MAX_SIZE_TEST
		)
		transformed_img = transform_gen.get_transform(image).apply_image(image)
		input_tensor = torch.as_tensor(transformed_img.astype("float32").transpose(2, 0, 1)).requires_grad_(True)
          
		return image, image_height, image_width, input_tensor
        
	def get_cam(self, img_path, target_instance):
		"""
		Calls the GradCAM instance

		Parameters
		----------
		img : str
			Path to inference image
		target_instance : int
			The target instance index
		layer_name : str
			Convolutional layer to perform GradCAM on
		grad_cam_type : str
			GradCAM or GradCAM++ (for multiple instances of the same object, GradCAM++ can be favorable)

		Returns
		-------
		image_dict : dict
			{"image" : <image>, "cam" : <cam>, "output" : <output>, "label" : <label>}
			<image> original input image
			<cam> class activation map resized to original image shape
			<output> instances object generated by the model
			<label> label of the 
		"""

		image, image_height, image_width, input_tensor = self._set_input_image(img_path)
		
		self.image = image
     
		input_image_dict = {"image": input_tensor, "height": image_height, "width": image_width}
		grad_cam = self.grad_cam_instance(self.model, self.layer_name)
		
		output = grad_cam(input_image_dict)["instances"]
	
		with grad_cam as cam:
			cam = cam.get_cam(output, target_instance=target_instance)
		
		if cam.size != 0:
			output_dict = self.get_output_dict(image, cam, output, target_instance)
			return output_dict
		
		else:
			self.image = image
			return None
    
	def get_output_dict(self, image, cam, output, target_instance):
		image_dict = {}
		image_dict["image"] =  image
		image_dict["cam"] = cam
		image_dict["output"] = output
		#   image_dict["label"] = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).thing_classes[output["instances"].pred_classes[target_instance]]
		return image_dict

	def clear(self):
		# self.image = self.image_height = self.image_width = self.input_tensor = None
          self.image = None
